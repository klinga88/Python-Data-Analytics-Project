{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to hold sentiments\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "\n",
    "#list to hold tweet data\n",
    "tweet_text = []\n",
    "tweet_times = []\n",
    "unique_ids = []\n",
    "tweet_user = []\n",
    "tweet_handle = []\n",
    "tweet_followers = []\n",
    "tweet_language = []\n",
    "tweet_search_keyword = []\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "ignore_user = ['melaniebower89a','oliverpaige625','victorblake392']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks = pd.read_csv(\"SP_100_Tickers.csv\")\n",
    "\n",
    "stock_keywords_description = top_stocks[\"Name\"].tolist()\n",
    "stock_keywords_symbol = top_stocks[\"Symbol\"].tolist()\n",
    "\n",
    "stock_keywords = stock_keywords_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through keywords\n",
    "for keyword in stock_keywords:\n",
    "    \n",
    "    #put tweeter searches in list\n",
    "    public_tweets = api.search(keyword,count = 100)\n",
    "    \n",
    "    \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "        \n",
    "        #Use filters to check if user meets conditions\n",
    "        if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "            tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "            tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "            tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "            tweet[\"user\"][\"lang\"] == lang and not tweet['retweeted'] and \n",
    "            'RT @' not in tweet['text'] and 'Binance' not in tweet['text'] and\n",
    "            tweet[\"user\"][\"screen_name\"] not in ignore_user):\n",
    "                        \n",
    "            tweet_id = tweet[\"id\"]\n",
    "            \n",
    "            # if Id is unique tweet data will be added\n",
    "            if tweet_id not in unique_ids:\n",
    "                \n",
    "                unique_ids.append(tweet_id)\n",
    "            \n",
    "                tweet_search_keyword.append(keyword)\n",
    "                tweet_text.append(tweet[\"text\"])\n",
    "                tweet_user.append(tweet[\"user\"][\"name\"])\n",
    "                tweet_handle.append(tweet[\"user\"][\"screen_name\"])\n",
    "                tweet_followers.append(tweet[\"user\"][\"followers_count\"])\n",
    "                tweet_language.append(tweet[\"user\"][\"lang\"])\n",
    "                tweet_times.append(tweet[\"created_at\"])\n",
    "\n",
    "                # Run Vader Analysis on each tweet and add to lists\n",
    "                compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "                compound_list.append(compound)\n",
    "\n",
    "                pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "                positive_list.append(pos)\n",
    "\n",
    "                neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "                neutral_list.append(neu)\n",
    "\n",
    "                neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "                negative_list.append(neg)\n",
    "\n",
    "\n",
    "            # Add each datetime object into the array\n",
    "            tweet_time_objects = []\n",
    "            for x in range(len(tweet_times)):\n",
    "                tweet_datetime = datetime.strptime(tweet_times[x], \"%a %b %d %H:%M:%S %z %Y\")\n",
    "                tweet_time_objects.append(tweet_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "---------\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n",
      "1416\n"
     ]
    }
   ],
   "source": [
    "#check to make sure all list are the same lenght\n",
    "print(len(tweet_search_keyword))\n",
    "print(len(tweet_user))\n",
    "print(len(tweet_handle))\n",
    "print(len(tweet_followers))\n",
    "print(len(tweet_language))\n",
    "print(len(unique_ids))\n",
    "print(\"---------\")\n",
    "print(len(tweet_text))\n",
    "print(len(tweet_time_objects))\n",
    "print(len(compound_list))\n",
    "print(len(positive_list))\n",
    "print(len(negative_list))\n",
    "print(len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.DataFrame({\"Search Term\": tweet_search_keyword,\n",
    "                            'Name':tweet_user,\n",
    "                           'Handle':tweet_handle,\n",
    "                           'Followers':tweet_followers,\n",
    "                           'Language' : tweet_language,\n",
    "                            'Id':unique_ids,\n",
    "                            'Text': tweet_text,\n",
    "                           'Time Stamp':tweet_time_objects,\n",
    "                           'Compound' : compound_list,\n",
    "                           'positive': positive_list,\n",
    "                           'negative': negative_list,\n",
    "                           'neutral': neutral_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tweet_data.iterrows():\n",
    "    \n",
    "    tweet_data[\"Date\"] = datetime.date(row[\"Time Stamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Average Sentiments\n",
    "sentiment = {\"Compound\": np.mean(compound_list),\n",
    "             \"Positive\": np.mean(positive_list),\n",
    "             \"Neutral\": np.mean(neutral_list),\n",
    "             \"Negative\": np.mean(negative_list)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
     ]
    }
   ],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_breakdown = []\n",
    "tweet_text_id = []\n",
    "\n",
    "for index, row in tweet_data.iterrows():\n",
    "    text_seperate = preprocess(row[\"Text\"])\n",
    "    tweet_text_breakdown.append(text_seperate)\n",
    "    text_seperate_id = row[\"Id\"]\n",
    "    tweet_text_id.append(text_seperate_id)\n",
    "\n",
    "text_breakdown_df = pd.DataFrame({'Id':tweet_text_id,\n",
    "                                   'Text Breakdown':tweet_text_breakdown})\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>Name</th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Text</th>\n",
       "      <th>Time Stamp</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>Text Breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>507</td>\n",
       "      <td>imnotbegging</td>\n",
       "      <td>1011368146249363456</td>\n",
       "      <td>en</td>\n",
       "      <td>just aj:(</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>@lizerdgurl PayPal: Mobile Cash by PayPal, Inc...</td>\n",
       "      <td>2018-06-25 21:58:51+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[@lizerdgurl, PayPal, :, Mobile, Cash, by, Pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>58</td>\n",
       "      <td>DonghanTurkey</td>\n",
       "      <td>1011366457563930627</td>\n",
       "      <td>en</td>\n",
       "      <td>Kim Donghan Turkey</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>₍🏆250618₎ ┊THE SHOW oylaması yarın yayınlanıyo...</td>\n",
       "      <td>2018-06-25 21:52:08+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[₍, 🏆, 250618, ₎, ┊, THE, SHOW, oylaması, yarı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>80</td>\n",
       "      <td>AppStoreNews24</td>\n",
       "      <td>1011363668716486656</td>\n",
       "      <td>en</td>\n",
       "      <td>App Store News</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>eBay: Discover Summer Deals - eBay Inc. https:...</td>\n",
       "      <td>2018-06-25 21:41:03+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[eBay, :, Discover, Summer, Deals, -, eBay, In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5267</td>\n",
       "      <td>337</td>\n",
       "      <td>lb_SFO</td>\n",
       "      <td>1011362391613833216</td>\n",
       "      <td>en</td>\n",
       "      <td>DCAFlyer</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>El CEO de Apple, Tim Cook, marcho ayer en el S...</td>\n",
       "      <td>2018-06-25 21:35:59+00:00</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.201</td>\n",
       "      <td>[El, CEO, de, Apple, ,, Tim, Cook, ,, marcho, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.2484</td>\n",
       "      <td>1843</td>\n",
       "      <td>CSB</td>\n",
       "      <td>1011359076058574848</td>\n",
       "      <td>en</td>\n",
       "      <td>Comic Strip Blogger</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>My new #cartoon :\\n\\nSiri and HomePod - the mo...</td>\n",
       "      <td>2018-06-25 21:22:48+00:00</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[My, new, #cartoon, :, Siri, and, HomePod, -, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound  Followers          Handle                   Id Language  \\\n",
       "0    0.0000        507    imnotbegging  1011368146249363456       en   \n",
       "1    0.0000         58   DonghanTurkey  1011366457563930627       en   \n",
       "2    0.0000         80  AppStoreNews24  1011363668716486656       en   \n",
       "3    0.5267        337          lb_SFO  1011362391613833216       en   \n",
       "4   -0.2484       1843             CSB  1011359076058574848       en   \n",
       "\n",
       "                  Name       Search Term  \\\n",
       "0            just aj:(  Apple Inc.         \n",
       "1   Kim Donghan Turkey  Apple Inc.         \n",
       "2       App Store News  Apple Inc.         \n",
       "3             DCAFlyer  Apple Inc.         \n",
       "4  Comic Strip Blogger  Apple Inc.         \n",
       "\n",
       "                                                Text  \\\n",
       "0  @lizerdgurl PayPal: Mobile Cash by PayPal, Inc...   \n",
       "1  ₍🏆250618₎ ┊THE SHOW oylaması yarın yayınlanıyo...   \n",
       "2  eBay: Discover Summer Deals - eBay Inc. https:...   \n",
       "3  El CEO de Apple, Tim Cook, marcho ayer en el S...   \n",
       "4  My new #cartoon :\\n\\nSiri and HomePod - the mo...   \n",
       "\n",
       "                 Time Stamp  negative  neutral  positive  \\\n",
       "0 2018-06-25 21:58:51+00:00     0.000    1.000     0.000   \n",
       "1 2018-06-25 21:52:08+00:00     0.000    1.000     0.000   \n",
       "2 2018-06-25 21:41:03+00:00     0.000    1.000     0.000   \n",
       "3 2018-06-25 21:35:59+00:00     0.079    0.719     0.201   \n",
       "4 2018-06-25 21:22:48+00:00     0.158    0.727     0.115   \n",
       "\n",
       "                                      Text Breakdown  \n",
       "0  [@lizerdgurl, PayPal, :, Mobile, Cash, by, Pay...  \n",
       "1  [₍, 🏆, 250618, ₎, ┊, THE, SHOW, oylaması, yarı...  \n",
       "2  [eBay, :, Discover, Summer, Deals, -, eBay, In...  \n",
       "3  [El, CEO, de, Apple, ,, Tim, Cook, ,, marcho, ...  \n",
       "4  [My, new, #cartoon, :, Siri, and, HomePod, -, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_all = pd.merge(tweet_data,text_breakdown_df[[\"Id\",\"Text Breakdown\"]], on=\"Id\",how=\"left\")\n",
    "\n",
    "tweet_data.to_csv(\"tweet_data_all.csv\")\n",
    "\n",
    "tweet_data_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
