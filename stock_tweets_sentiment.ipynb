{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to hold sentiments\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "\n",
    "#list to hold tweet data\n",
    "tweet_text = []\n",
    "tweet_times = []\n",
    "unique_ids = []\n",
    "tweet_user = []\n",
    "tweet_handle = []\n",
    "tweet_followers = []\n",
    "tweet_language = []\n",
    "tweet_search_keyword = []\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "ignore_user = ['melaniebower89a','oliverpaige625','victorblake392']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks = pd.read_csv(\"NYSE_20180622_top50.csv\")\n",
    "\n",
    "stock_keywords_description = top_stocks[\"Description\"].tolist()\n",
    "stock_keywords_symbol = top_stocks[\"Symbol\"].tolist()\n",
    "\n",
    "stock_keywords = stock_keywords_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through keywords\n",
    "for keyword in stock_keywords:\n",
    "    \n",
    "    #put tweeter searches in list\n",
    "    public_tweets = api.search(keyword,count = 500)\n",
    "    \n",
    "    \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "        \n",
    "        #Use filters to check if user meets conditions\n",
    "        if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "            tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "            tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "            tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "            tweet[\"user\"][\"lang\"] == lang and not tweet['retweeted'] and \n",
    "            'RT @' not in tweet['text'] and 'Binance' not in tweet['text'] and\n",
    "            tweet[\"user\"][\"screen_name\"] not in ignore_user):\n",
    "                        \n",
    "            tweet_id = tweet[\"id\"]\n",
    "            \n",
    "            # if Id is unique tweet data will be added\n",
    "            if tweet_id not in unique_ids:\n",
    "                \n",
    "                unique_ids.append(tweet_id)\n",
    "            \n",
    "                tweet_search_keyword.append(keyword)\n",
    "                tweet_text.append(tweet[\"text\"])\n",
    "                tweet_user.append(tweet[\"user\"][\"name\"])\n",
    "                tweet_handle.append(tweet[\"user\"][\"screen_name\"])\n",
    "                tweet_followers.append(tweet[\"user\"][\"followers_count\"])\n",
    "                tweet_language.append(tweet[\"user\"][\"lang\"])\n",
    "                tweet_times.append(tweet[\"created_at\"])\n",
    "\n",
    "                # Run Vader Analysis on each tweet and add to lists\n",
    "                compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "                compound_list.append(compound)\n",
    "\n",
    "                pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "                positive_list.append(pos)\n",
    "\n",
    "                neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "                neutral_list.append(neu)\n",
    "\n",
    "                neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "                negative_list.append(neg)\n",
    "\n",
    "\n",
    "            # Add each datetime object into the array\n",
    "            tweet_time_objects = []\n",
    "            for x in range(len(tweet_times)):\n",
    "                tweet_datetime = datetime.strptime(tweet_times[x], \"%a %b %d %H:%M:%S %z %Y\")\n",
    "                tweet_time_objects.append(tweet_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure all list are the same lenght\n",
    "print(len(tweet_search_keyword))\n",
    "print(len(tweet_user))\n",
    "print(len(tweet_handle))\n",
    "print(len(tweet_followers))\n",
    "print(len(tweet_language))\n",
    "print(len(unique_ids))\n",
    "print(\"---------\")\n",
    "print(len(tweet_text))\n",
    "print(len(tweet_time_objects))\n",
    "print(len(compound_list))\n",
    "print(len(positive_list))\n",
    "print(len(negative_list))\n",
    "print(len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.DataFrame({\"Search Term\": tweet_search_keyword,\n",
    "                            'Name':tweet_user,\n",
    "                           'Handle':tweet_handle,\n",
    "                           'Followers':tweet_followers,\n",
    "                           'Language' : tweet_language,\n",
    "                            'Id':unique_ids,\n",
    "                            'Text': tweet_text,\n",
    "                           'Time Stamp':tweet_time_objects,\n",
    "                           'Compound' : compound_list,\n",
    "                           'positive': positive_list,\n",
    "                           'negative': negative_list,\n",
    "                           'neutral': neutral_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tweet_data.iterrows():\n",
    "    \n",
    "    tweet_data[\"Date\"] = datetime.date(row[\"Time Stamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Average Sentiments\n",
    "sentiment = {\"Compound\": np.mean(compound_list),\n",
    "             \"Positive\": np.mean(positive_list),\n",
    "             \"Neutral\": np.mean(neutral_list),\n",
    "             \"Negative\": np.mean(negative_list)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_breakdown = []\n",
    "tweet_text_id = []\n",
    "\n",
    "for index, row in tweet_data.iterrows():\n",
    "    text_seperate = preprocess(row[\"Text\"])\n",
    "    tweet_text_breakdown.append(text_seperate)\n",
    "    text_seperate_id = row[\"Id\"]\n",
    "    tweet_text_id.append(text_seperate_id)\n",
    "\n",
    "text_breakdown_df = pd.DataFrame({'Id':tweet_text_id,\n",
    "                                   'Text Breakdown':tweet_text_breakdown})\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_all = pd.merge(tweet_data,text_breakdown_df[[\"Id\",\"Text Breakdown\"]], on=\"Id\",how=\"left\")\n",
    "\n",
    "tweet_data.to_csv(\"tweet_data_all.csv\")\n",
    "\n",
    "tweet_data_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
